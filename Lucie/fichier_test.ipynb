{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a771d02",
   "metadata": {},
   "source": [
    "-------\n",
    "## Prédiction de la Polarité - MLP\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ae087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "============================================================\n",
      "RÉSULTATS DE PERFORMANCE (Groupe 3 - MLP)\n",
      "Précision (Accuracy) : 0.8202\n",
      "F1-Score (pondéré)    : 0.8378\n",
      "Perte (Log Loss)      : 0.4471\n",
      "\n",
      "------------------------------------------------------------\n",
      "Rapport détaillé :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      neutre       0.33      0.57      0.42       488\n",
      "     négatif       0.83      0.85      0.84      1131\n",
      "     positif       0.96      0.85      0.90      3381\n",
      "\n",
      "    accuracy                           0.82      5000\n",
      "   macro avg       0.70      0.76      0.72      5000\n",
      "weighted avg       0.87      0.82      0.84      5000\n",
      "\n",
      "\n",
      "============================================================\n",
      "Fichier 'Resultat_POLARITE_Groupe3_MLP.csv' généré avec succès.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, log_loss\n",
    "\n",
    "model = tf.keras.models.load_model('model_polarite.keras')\n",
    "\n",
    "with open('tfidf_polarite.pkl', 'rb') as f:\n",
    "    tfidf = pickle.load(f)\n",
    "    \n",
    "with open('label_encoder_polarite.pkl', 'rb') as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Nettoyage du texte selon votre Cellule 5\"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)       # enlever liens\n",
    "    text = re.sub(r\"[^a-z\\s']\", \" \", text)     # garder lettres et apostrophes\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()   # espaces propres\n",
    "    return text\n",
    "\n",
    "def label_polarity(score):\n",
    "    \"\"\"Conversion des étoiles en classes selon votre Cellule 5\"\"\"\n",
    "    if score > 3: return \"positif\"\n",
    "    elif score < 3: return \"négatif\"\n",
    "    else: return \"neutre\"\n",
    "\n",
    "file_prof = r'C:\\Users\\lucie\\OneDrive\\Documents\\SEMESTRE_6\\test\\Test_file_SAE.json'\n",
    "df_prof = pd.read_json(file_prof, lines=True)\n",
    "\n",
    "texts_cleaned = df_prof['text'].apply(clean_text)\n",
    "# Vectorisation TF-IDF (conversion en matrice dense pour le MLP)\n",
    "X_prof_tfidf = tfidf.transform(texts_cleaned).toarray()\n",
    "\n",
    "df_prof['label_reel'] = df_prof['stars'].apply(label_polarity)\n",
    "y_true_indices = le.transform(df_prof['label_reel'])\n",
    "\n",
    "# Prédictions\n",
    "predictions_probs = model.predict(X_prof_tfidf)\n",
    "predictions_indices = predictions_probs.argmax(axis=1)\n",
    "\n",
    "df_prof['prediction'] = le.inverse_transform(predictions_indices)\n",
    "\n",
    "acc = accuracy_score(y_true_indices, predictions_indices)\n",
    "f1_weighted = f1_score(y_true_indices, predictions_indices, average='weighted')\n",
    "loss = log_loss(y_true_indices, predictions_probs)\n",
    "\n",
    "target_names = [str(cls) for cls in le.classes_]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"RÉSULTATS DE PERFORMANCE (Groupe 3 - MLP)\")\n",
    "print(f\"Précision (Accuracy) : {acc:.4f}\")\n",
    "print(f\"F1-Score (pondéré)    : {f1_weighted:.4f}\")\n",
    "print(f\"Perte (Log Loss)      : {loss:.4f}\")\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Rapport détaillé :\\n\")\n",
    "print(classification_report(y_true_indices, predictions_indices, target_names=target_names))\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Sauvegarde finale avec les colonnes d'origine et la prédiction\n",
    "df_prof.to_csv('Resultat_POLARITE_Groupe3_MLP.csv', index=False)\n",
    "print(\"Fichier 'Resultat_POLARITE_Groupe3_MLP.csv' généré avec succès.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae63813",
   "metadata": {},
   "source": [
    "-------\n",
    "## Prédiction score (étoiles) - MLP\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\n",
      "============================================================\n",
      "RÉSULTATS DE PERFORMANCE - MODÈLE ÉTOILES\n",
      "Précision (Accuracy) : 0.6094\n",
      "F1-Score (pondéré)    : 0.6213\n",
      "Perte (Log Loss)      : 0.8912\n",
      "\n",
      "------------------------------------------------------------\n",
      "Rapport détaillé par nombre d'étoiles :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 1 étoile(s)       0.77      0.71      0.74       747\n",
      " 2 étoile(s)       0.35      0.41      0.38       384\n",
      " 3 étoile(s)       0.42      0.41      0.41       488\n",
      " 4 étoile(s)       0.43      0.59      0.49      1096\n",
      " 5 étoile(s)       0.81      0.66      0.73      2285\n",
      "\n",
      "    accuracy                           0.61      5000\n",
      "   macro avg       0.55      0.56      0.55      5000\n",
      "weighted avg       0.65      0.61      0.62      5000\n",
      "\n",
      "============================================================\n",
      "Fichier 'Resultat_ETOILES_Groupe3_MLP.csv' généré avec succès.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, log_loss\n",
    "\n",
    "model = tf.keras.models.load_model('model_etoiles.keras')\n",
    "with open('tfidf_etoiles.pkl', 'rb') as f:\n",
    "    tfidf = pickle.load(f)\n",
    "    \n",
    "with open('label_encoder_etoiles.pkl', 'rb') as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)       # enlever les liens\n",
    "    text = re.sub(r\"[^a-z\\s']\", \" \", text)     # garder lettres et apostrophes\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()   # espaces propres\n",
    "    return text\n",
    "\n",
    "file_prof = r'C:\\Users\\lucie\\OneDrive\\Documents\\SEMESTRE_6\\test\\Test_file_SAE.json'\n",
    "df_prof = pd.read_json(file_prof, lines=True)\n",
    "\n",
    "texts_cleaned = df_prof['text'].apply(clean_text)\n",
    "\n",
    "X_prof_tfidf = tfidf.transform(texts_cleaned).toarray()\n",
    "y_true_indices = le.transform(df_prof['stars'])\n",
    "\n",
    "# Prédiction des probabilités\n",
    "predictions_probs = model.predict(X_prof_tfidf)\n",
    "predictions_indices = predictions_probs.argmax(axis=1)\n",
    "df_prof['prediction_etoile'] = le.inverse_transform(predictions_indices)\n",
    "\n",
    "acc = accuracy_score(y_true_indices, predictions_indices)\n",
    "f1_weighted = f1_score(y_true_indices, predictions_indices, average='weighted')\n",
    "loss = log_loss(y_true_indices, predictions_probs)\n",
    "\n",
    "target_names = [f\"{cls} étoile(s)\" for cls in le.classes_]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"RÉSULTATS DE PERFORMANCE - MODÈLE ÉTOILES\")\n",
    "print(f\"Précision (Accuracy) : {acc:.4f}\")\n",
    "print(f\"F1-Score (pondéré)    : {f1_weighted:.4f}\")\n",
    "print(f\"Perte (Log Loss)      : {loss:.4f}\")\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Rapport détaillé par nombre d'étoiles :\\n\")\n",
    "print(classification_report(y_true_indices, predictions_indices, target_names=target_names))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sauvegarde du fichier final\n",
    "df_prof.to_csv('Resultat_ETOILES_Groupe3_MLP.csv', index=False)\n",
    "print(\"Fichier 'Resultat_ETOILES_Groupe3_MLP.csv' généré avec succès.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
